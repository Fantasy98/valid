{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 07:56:56.419672: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-04 07:56:56.760059: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-04 07:56:57.664872: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.3/lib64${LD_LIBRARY_PATH:+:/usr/lib/cuda/include:/usr/lib/cuda/lib64:}\n",
      "2022-12-04 07:56:57.664947: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.3/lib64${LD_LIBRARY_PATH:+:/usr/lib/cuda/include:/usr/lib/cuda/lib64:}\n",
      "2022-12-04 07:56:57.664954: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from DataHandling.features import slices\n",
    "from DataHandling.features.slices import read_tfrecords,feature_description\n",
    "from DataHandling import utility\n",
    "from DataHandling.models import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 07:57:00.133427: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-04 07:57:00.160546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-04 07:57:00.160892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "os.environ['WANDB_DISABLE_CODE']='True'\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[-1], True)\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "var=['u_vel',\"v_vel\",\"w_vel\",\"pr0.025\"]\n",
    "target=['pr0.025_flux']\n",
    "normalized=False\n",
    "y_plus=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuning/thesis/valid/scratch/test\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = \"/home/yuning/thesis/valid/scratch\"\n",
    "path_test = os.path.join(file_path,\"test\")\n",
    "print(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset(\n",
    "                                    filenames=path_test,\n",
    "                                    compression_type=\"GZIP\",\n",
    "                                    num_parallel_reads=tf.data.experimental.AUTOTUNE\n",
    "                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'u_vel': FixedLenFeature(shape=[], dtype=tf.string, default_value=''),\n",
       " 'v_vel': FixedLenFeature(shape=[], dtype=tf.string, default_value=''),\n",
       " 'w_vel': FixedLenFeature(shape=[], dtype=tf.string, default_value=''),\n",
       " 'pr0.025': FixedLenFeature(shape=[], dtype=tf.string, default_value=''),\n",
       " 'pr0.025_flux': FixedLenFeature(shape=[], dtype=tf.string, default_value='')}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dict = feature_description(file_path)\n",
    "feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x: read_tfrecords(x,feature_dict,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DatasetV2.snapshot of <MapDataset element_spec=({'pr0.025': TensorSpec(shape=<unknown>, dtype=tf.float64, name=None), 'u_vel': TensorSpec(shape=<unknown>, dtype=tf.float64, name=None), 'v_vel': TensorSpec(shape=<unknown>, dtype=tf.float64, name=None), 'w_vel': TensorSpec(shape=<unknown>, dtype=tf.float64, name=None)}, TensorSpec(shape=<unknown>, dtype=tf.float64, name=None))>>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pr0.025', 'u_vel', 'v_vel', 'w_vel'])\n"
     ]
    }
   ],
   "source": [
    "u_vel = []\n",
    "v_vel = []\n",
    "w_vel = []\n",
    "pr0025 = []\n",
    "pr0025_flux = []\n",
    "for ele in dataset.as_numpy_iterator():\n",
    "    print(ele[0].keys())\n",
    "    \n",
    "    # tuple(dict) thus ele[0] we get dict and accroding to its key we git value\n",
    "    # u_vel.append(ele[0][\"u_vel\"])\n",
    "    # v_vel.append(ele[0][\"v_vel\"])\n",
    "    # w_vel.append(ele[0][\"w_vel\"])\n",
    "    # pr0025.append(ele[0][\"pr0.025\"])\n",
    "    # pr0025_flux.append(ele[0][\"pr0.025_flux\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 407  snapshots of u in test dataset \n",
      "There are 407  snapshots of v in test dataset \n",
      "There are 407  snapshots of w in test dataset \n",
      "There are 407  snapshots of pr0.025 in test dataset \n"
     ]
    }
   ],
   "source": [
    "print(\"There are {}  snapshots of u in test dataset \".format(len(u_vel)))\n",
    "print(\"There are {}  snapshots of v in test dataset \".format(len(v_vel)))\n",
    "print(\"There are {}  snapshots of w in test dataset \".format(len(w_vel)))\n",
    "print(\"There are {}  snapshots of pr0.025 in test dataset \".format(len(pr0025)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are (407, 256, 256)  snapshots of u in test dataset \n",
      "There are (407, 256, 256)  snapshots of v in test dataset \n",
      "There are (407, 256, 256)  snapshots of w in test dataset \n",
      "There are (407, 256, 256)  snapshots of pr0.025 in test dataset \n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "U_data = np.array(u_vel)\n",
    "V_data = np.array(v_vel)\n",
    "W_data = np.array(w_vel)\n",
    "Pr_data = np.array(pr0025)\n",
    "print(\"There are {}  snapshots of u in test dataset \".format(U_data.shape))\n",
    "print(\"There are {}  snapshots of v in test dataset \".format(V_data.shape))\n",
    "print(\"There are {}  snapshots of w in test dataset \".format(W_data.shape))\n",
    "print(\"There are {}  snapshots of pr0.025 in test dataset \".format(Pr_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DatasetV2.snapshot of <PrefetchDataset element_spec=TensorSpec(shape=(None, 256, 256), dtype=tf.float64, name=None)>>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_TF = tf.data.Dataset.from_tensor_slices(U_data)\n",
    "U_TF = U_TF.batch(batch_size=8)\n",
    "U_TF = U_TF.shuffle(buffer_size=100)\n",
    "U_TF = U_TF.repeat(2)\n",
    "U_TF = U_TF.prefetch(3)\n",
    "\n",
    "U_TF.snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data.experimental.save(U_TF,os.path.join(file_path,\"u_vel\"),compression=\"GZIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_shard_func(element):\n",
    "#   return np.int64(0)\n",
    "tf.data.experimental.save(U_TF,os.path.join(file_path,\"u_vel\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_U = tf.data.Dataset.load(os.path.join(file_path,\"u_vel\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DatasetV2.snapshot of <PrefetchDataset element_spec=TensorSpec(shape=(None, 256, 256), dtype=tf.float64, name=None)>>\n",
      "<bound method DatasetV2.snapshot of <_LoadDataset element_spec=TensorSpec(shape=(None, 256, 256), dtype=tf.float64, name=None)>>\n"
     ]
    }
   ],
   "source": [
    "print(U_TF.snapshot)\n",
    "print(DATA_U.snapshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "for ele in DATA_U.as_numpy_iterator():\n",
    "    print(ele.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tensor2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Oct 21 2022, 23:50:54) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11e05876bec2ad9b34c669d9dff61cc48fedec39522fd08af25791e3a216550b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
